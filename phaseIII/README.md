Austin Devine
Avery Pound
Dominic London
Phase III: Prototype Testing
<br>
Introduction:
	The Student Scheduler User Engineering team, consisting of Austin Devine, Avery Pound, and Dominic London, has been working to gain insight into the user experience regarding our new product: Student Scheduler. This website, and eventually app, will allow users to schedule their extra-curricular activities around their classes and vice versa. Its main draws are that it has additional features compared to similar programs, while also being easier to use. In our latest tests, we gave potential users a chance to try our software. This provided great insight into our potential user base as we learned not only how our users will use the software, but also what they thought. While our tests provided great insight, we learned that our design is not ready for release at this time.
<br>
Methods:
	Our study consisted of analyzing five potential users using our software while learning about their feelings regarding not only our software, but the software of our competitors. We started off with a questionnaire asking users a variety of questions about the software and tools they use to schedule their classes and extracurricular activities. These questions included, 
“Do you schedule your classes on your own; unassisted? (This includes parents, advisors, or friends),” 
“What programs have you used to schedule your classes? (Have you used more than one school’s program?) List all tools you use or have used when scheduling your classes, including pen and paper or other software,” 
“Are there any features you can recall from memory that you find especially useful when trying to find classes to schedule, and then scheduling said classes?” 
“How would you rate your experiences with other programs you have used on a scale of 1-10 in the following categories?”
Finding Classes
Scheduling Classes
Scheduling Classes around extracurricular activities.
At this point we asked our participants to complete a series of tasks using a prototype created in Adobe XD. Before having the participants complete the task, we explained that we expect a participant that they represent will have used the program before, and there are some pre-existing user generated items that they will not have to create. We then proceeded to administer the tasks. These tasks were as follows:
“We want you to login and create a new recurring event, one hour of going to the gym.”
“Assuming you have used this software before and already added an extra curricular event to your profile, we want you to add the already existing event to your schedule. In this case, add ‘Milo’s Piano Lesson.’ This task is NOT dependent on your success on Task 1”
“We want you to delete one of the classes from your schedule. The class you have already signed up for is CSCI 511.”
As the participants were completing the tasks we took careful notes about what they said, as well as how they interacted with our program. What they clicked on, where they moved the mouse, what they said they were looking for. After the participants had finished their attempt, we asked the participants to answer a few follow up questions. These were:
“Were there any features you expected that were not present or otherwise hard to find?”
“How would you rate your experiences with our program on a scale of 1-10 in the following categories?”
Finding buttons you were looking for?
Scheduling classes and events?
Do you have any other thoughts or comments?



Relay design recommendations.

method: n = 5 (number of participants)

Findings: 
	We found that all of our participants schedule their classes on their own, and they all use the chico state scheduler. One participant mentioned that they use Shasta college’s as well while another participant said they used excel for keeping track of the times of their classes. We received some decent feedback regarding what features participants find useful when scheduling classes. These included, “seeing classes in a ‘calendar’ view,” “being able to see the schedule with classes in the cart,” and three of our participants said “Student Scheduler,” with one mentioning how it shows you the various possibilities of classes you can take. Questions 4A-4C were quantitative, asking our users to rank their previous experiences. After analyzing the data we found the statistics for question 4A-4C listed below. You can find a further breakdown in chart 1
 4A: Finding Classes
Max: 8
Min: 6
Median 7
4B: Scheduling Classes
Max: 9
Min: 6
Median 7
4C: Scheduling Classes around extracurricular activities
Max: 10
Min: 2
Median: 5

This is where we had users try and complete tasks.

	TASK 1
When completing task 1, all participants were able to complete their task in about a minute or less. They also completed it exactly how it was expected. That being said, we did receive some common feedback. Two of our participants mentioned how there was no indication of the timing of the event. With regards to this criticism, we had a dual-ended, adjustable bar for setting the time, however the slider bar was not labeled, there were no times in the window, and we were not able to implement the event displaying in our calendar. This created a major problem because participants should be able to see and control when the event takes place. The fact that they were the only two participants that mentioned this brings up another issue, we should probably include setting a time, as part of the task. This issue was extremely bothersome for one participant, despite it not technically being an issue for completing the task, they felt compelled to figure out how to set the time. They seemed to understand the bar had something to do with the time but were unclear as to what do with it. This made them want to give up on the task. We encouraged them to disregard the timing and to try and complete creating an event regardless and they were able to finish the task successfully. 
TASK 2
In task 2, things got a little more dicey. Not only did most of our participants get tripped up, they all had different ideas and comments about adding events to their schedule. Our first participant had the right idea, but got stuck when he had to click the “+” button. This was a common thread in our testing of this task. It seemed that most participants felt they should be able to simply click on the event and that should complete the task. After a moment or two participant 1 saw the button and completed the task. The second participant had a nearly identical process. He clicked on the event expecting it to be added but seemed surprised it wasn’t. He looked around the screen and said, “I’m looking for a ‘+ and -’ button but I don’t see one,” which he immediately found after stating that. Our next participant had some confusion not with the plus or minus button, but with button functionality. In our home page we have a button labeled, “Create Event” and a button labeled, “Add Event.” He initially clicked on the Create Event button. He realized that he clicked the wrong button, went back to the main menu and completed the task successfully. Our next participant clicked the correct button to add an existing event but he also got confused with the +/- buttons. This participant felt that those buttons most likely meant  “zoom in and zoom out.” However, with experimenting he was able to complete his tasks. As our final participant attempted task 2 he was able to do so with relative ease. However he did note that the event he was supposed to click, was highlighted by default, which confused him. While this is an issue worth resolving it is an issue with our prototype, not the design.  ‘
Task 3
Almost all participants completed the task quickly and easily. 
After the tasks, we asked a few follow up questions. The first was asking if there were any features they expected but weren’t present. Most participants said no, but one said that creating an event needs a way to control time, and another said that the profile button should be clickable. While not necessary to complete the tasks, we believe that the participant who says the profile button should be clickable may have thought that was how to see a list of the pre-existing events. As such, for further testing, we should try and include a page that shows what clicking the profile will look like.
	We then asked participants to rate their experience with our software on a scale 1-10 in regards to finding buttons they were looking for and for scheduling classes or events. Most of our patrons gave us good ratings, with 80% giving us a rating of 8/10 or better for both categories (See table 2 for further details). One interesting finding was that 40% of our users found it easier to schedule classes, 20% said it was about the same, and 40% actually found it harder. However, even those whose rankings were lower than the original still gave us an 8/10. Because this was an analysis of statistic scores, and not explicitly a comparison when we asked participants how they felt, we are slightly skeptical that these values don’t necessarily reflect that we are worse. Further investigation may be required.
	Finally we asked users if they had any additional comments and we received great feedback. Some very praiseworthy, and some highly constructive. One participant used comments saying, “Pretty Good,” “Well laid out,” “I appreciate always seeing the Calendar” and they also mentioned the product would be even better if there was some color coordination. Our next participant was more critical, they brought up the fact that there was no time on our prototype for creating events, and they also mentioned that the boxes representing classes and events didn’t have any information in them. We feel both of these suggestions would be great to add for the final product and possibly our prototype as well. One participant unfortunately said our program was, “Confusing,” which we will try to work on. Another tester criticized our prototype for its limited functionality. This same tester also criticized that there should be a back button. However seeing how this was presented in a web format, the browser window typically comes with a back button. We believe they may be referring to the limited functionality of our prototype. Finally our last participant simply commented that we did a “Good Job.”
Most of our users commented that our software was good. One commented that they  really liked the ability to see the calendar at all times, while a more critical feedback was that they’d like to see information in the boxes on the calendar. We also found that users were a little confused about how to add events to their calendar. Most understood that they needed to click on the event, but they saw no confirmation, after a moment or two many realized that they needed to click on the “+” button to complete the task. One particular individual noted that they didn’t feel they had completed the task even though they had. This is because they didn’t see their calendar update, however this was a limitation of our prototype, and their expectation of what would happen was correct.

(Use graphs/ charts/ tables instead of average (no pie chart) (good: stacked bar chart)) 
[1][2][  3   ][4][        5     ]

Add class task


Conclusion:

During this process we learned a lot about our users, our prototype and our design. First and foremost, as we mentioned earlier, 40% of our users gave our program a ranking lower than what they normally use. This is important because in addition to additional features, what is supposed to set our software apart from our competitors is that our software is easier to use. For our software to be successful we need it to be better for the vast majority of users. With 40% of our users saying it’s more difficult, we either need to redesign the software, or run more test cases. Due to the fact that we only ran the test with 5 people, each individual’s input carries monumental weight of 20%. 40% sounds like a lot, but two testers does not.

In this process we learned a lot about our users and how they think. Some of the things they liked about our software was the calendar view, the simplicity of the design, and the layout (although this was nullified by another participant). In addition to the layout, another element that was disliked was the time bar. This may not be a bad element in and of itself, however it is definitely worth making adjustments to our prototype to correct this. We can put time labels above each of the orbs indicating that the orbs represent various time and hopefully the user will deduce that one represents starting time and one represents ending time. Some things users had trouble with were the time bar, the +/- buttons, and the main menu buttons. As a designer I believe the time bar criticism is an extremely valid criticism and something we should work to resolve both in our design and prototype. The +/- buttons weren’t exactly troubling to most if any users but they were an unexpected hurdle to completing the task. I recommend we remove the buttons and instead give each task something along the lines of an on/off digital switch. As for the buttons we could probably reword them to give them some better clarity. We could probably combine “Delete Class” with “Delete Event” and have the user navigate between the two with a tab at the top of the menu.
	It’s also important to recognize where our users made incorrect assumptions about what to do. This provides good insight that we don’t have an optimal hierarchy of information. The first notable incorrect assumption was to click on the user icon. We believe this was because they thought that is where their saved events and classes may be. If they just wanted to view their saved events, maybe a button that says “View All events” would help them find what they are looking for. 
When we eventually do additional testing, we need to make some revisions to our protocol. As mentioned in our findings, some of our participants gave us a worse score on scheduling than expected. Most of our participants liked our software giving it a rating of 8/10 or better so we were surprised to discover that our scores were worse. This made us slightly skeptical about the implications of this and we started considering that maybe our participants weren’t paying super close attention to the scores they gave before, so we would recommend adding an additional question along the lines of “Do you believe our software was easier to use than what you have used before?” as this would give validity to whether or not the scores accurately reflect whether our software was better or worse. 
We would also highly recommend adding a task or sub-task about setting the time of an event when creating it. It’s important because multiple participants expressed concern about not knowing how to set the time when it wasn’t even necessary to complete the task. If it stood out to them that much, its probably worth looking into and fixing. 

Prototype - 
Relatively fully functional as opposed to just core functionality. For example we didn’t think participants would find the profile icon to be relevant so we didn’t program any functionality for it. However sometimes participants don’t think the same way we do and they click on and try to interact with items in a way the developers don’t anticipate. As developers of the prototype we should anticipate this.
Develop our prototype to give real time feedback. 
Some elements of our wireframe got carried over into our prototype. In our wireframe a particular event or class was highlighted to illustrate how a button might interact with an item on screen. In our prototype this functionality remained both present and static which caused confusion in some of our participants. We absolutely need to either program this dynamically, or remove this snapshot of a would be animation.
One participant was confused by the functionality of our time bar. As designers we hoped that they would realize they can click and drag on the orbs to change the time, but for this participant we don’t think they were aware they would be able to interact with this component in this way. This is another element that should probably be programmed.
One participant was confused about whether or not he had completed a task because there was nothing indicating that anything had changed.

Design
We need to add time labels to the time bar when creating an event.
Remove the “+/-” buttons and instead have the user click on the activity they want to add or remove,  perhaps this could be indicated with some events having automatically determined check-boxes suggesting that they are or are not currently in the schedule.



Discoveries made, critiques about prototype - revisions to design or prototype, missing, features




Caveats: Our sample size is small, same background, Didn’t test them based on their ability to…, possibly poor clarity of questions,


15 minute time intervals,
